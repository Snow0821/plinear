# -*- coding: utf-8 -*-
"""cifar100_vit_transformers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JuISll8IgP41d6gfRs8O6HD1vycg3AP1
"""

# !pip install pytorch-lightning

"""# Model

## Core
"""

import torch

def posNet(w: torch.Tensor):
    return (w > 0).float()

#RMSNorm : https://github.com/microsoft/unilm/blob/master/YOCO/yoco/models/decoder/rms_norm.py
def RMSNorm(x, eps: float = 1e-6):
    return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + eps)

"""## Binarized Ternary Neural Networks

### Linear
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class btnnLinear(nn.Module):
    def __init__(self, x, y):
        super(btnnLinear, self).__init__()
        self.pr = nn.Linear(x, y)
        self.nr = nn.Linear(x, y)

        torch.nn.init.uniform_(self.pr.weight, -1, 1)
        torch.nn.init.uniform_(self.nr.weight, -1, 1)

    def forward(self, x):
        pr = self.pr.weight
        nr = self.nr.weight
        qpr = posNet(pr)
        qnr = posNet(nr)

        # Apply quantization using posNet with detach
        qpr = qpr - pr.detach() + pr
        qnr = qnr - nr.detach() + nr

        # Compute linear transformations
        yr = F.linear(x, qpr) - F.linear(x, qnr)

        return yr

"""### Conv2d"""

class btnnConv2d(nn.Module):
    def __init__(self, x, y, kernel_size, stride=1, padding=0, groups = 1):
        super(btnnConv2d, self).__init__()
        self.pr = nn.Conv2d(x, y, kernel_size, stride=stride, padding=padding, groups=groups, bias=False)
        self.nr = nn.Conv2d(x, y, kernel_size, stride=stride, padding=padding, groups=groups, bias=False)

        torch.nn.init.uniform_(self.pr.weight, -1, 1)
        torch.nn.init.uniform_(self.nr.weight, -1, 1)

    def forward(self, x):
        pr = self.pr.weight
        nr = self.nr.weight
        qpr = posNet(pr)
        qnr = posNet(nr)

        # Apply quantization using posNet with detach
        qpr = qpr - pr.detach() + pr
        qnr = qnr - nr.detach() + nr

        # 양자화된 가중치로 Conv2d 수행
        ypr = F.conv2d(
            x,
            qpr,
            bias=None,
            stride=self.pr.stride,
            padding=self.pr.padding,
            dilation=self.pr.dilation,
            groups=self.pr.groups
        )

        ynr = F.conv2d(
            x,
            qnr,
            bias=None,
            stride=self.nr.stride,
            padding=self.nr.padding,
            dilation=self.nr.dilation,
            groups=self.nr.groups
        )

        return ypr - ynr

"""### Conv1d"""

class btnnConv1d(nn.Module):
    def __init__(self, x, y, kernel_size, stride=1, padding=0, groups = 1):
        super(btnnConv1d, self).__init__()
        self.pr = nn.Conv1d(x, y, kernel_size, stride=stride, padding=padding, groups=groups, bias=False)
        self.nr = nn.Conv1d(x, y, kernel_size, stride=stride, padding=padding, groups=groups, bias=False)

        torch.nn.init.uniform_(self.pr.weight, -1, 1)
        torch.nn.init.uniform_(self.nr.weight, -1, 1)

    def forward(self, x):
        pr = self.pr.weight
        nr = self.nr.weight

        qpr = posNet(pr)
        qnr = posNet(nr)

        qpr = qpr - pr.detach() + pr
        qnr = qnr - nr.detach() + nr

        ypr = F.conv1d(
            x,
            qpr,
            bias=None,
            stride=self.pr.stride,
            padding=self.pr.padding,
            dilation=self.pr.dilation,
            groups=self.pr.groups
        )

        ynr = F.conv1d(
            x,
            qnr,
            bias=None,
            stride=self.nr.stride,
            padding=self.nr.padding,
            dilation=self.nr.dilation,
            groups=self.nr.groups
        )

        return ypr - ynr

"""### RMSNorm"""

class btnnRMSNorm(nn.Module):
    def __init__(self):
        super(btnnRMSNorm, self).__init__()

    def forward(self, x):
        return RMSNorm(x)

"""### Binarited Ternary Attention"""

class btAttn(nn.Module):
    def __init__(self, dim, num_heads):
        super(btAttn, self).__init__()
        self.q = btnnLinear(dim, dim)
        self.k = btnnLinear(dim, dim)
        self.v = btnnLinear(dim, dim)
        self.mixer = btnnConv1d(num_heads, num_heads, 1)

    def forward(self, x):
        q, k, v = self.q(x), self.k(x), self.v(x)
        attn = q * k


        return self.mixer(attn * v)

"""### Models"""

"""
Code for CAS-ViT
"""

import torch
import torch.nn as nn
from torch.cuda.amp import autocast

import numpy as np
from einops import rearrange, repeat
import itertools
import os
import copy

from timm.models.layers import DropPath, trunc_normal_, to_2tuple
from timm.models.registry import register_model

# ======================================================================================================================
def stem(in_chs, out_chs, conv2d = nn.Conv2d):
    return nn.Sequential(
        conv2d(in_chs, out_chs // 2, kernel_size=3, stride=2, padding=1),
        nn.BatchNorm2d(out_chs // 2),
        nn.ReLU(),
        conv2d(out_chs // 2, out_chs, kernel_size=3, stride=2, padding=1),
        nn.BatchNorm2d(out_chs),
        nn.ReLU(), )

class Embedding(nn.Module):
    """
    Patch Embedding that is implemented by a layer of conv.
    Input: tensor in shape [B, C, H, W]
    Output: tensor in shape [B, C, H/stride, W/stride]
    """

    def __init__(self, patch_size=16, stride=16, padding=0,
                 in_chans=3, embed_dim=768, norm_layer=nn.BatchNorm2d,
                 conv2d = nn.Conv2d):
        super().__init__()
        patch_size = to_2tuple(patch_size)
        stride = to_2tuple(stride)
        padding = to_2tuple(padding)
        self.proj = conv2d(in_chans, embed_dim, kernel_size=patch_size,
                              stride=stride, padding=padding)
        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()

    def forward(self, x):
        x = self.proj(x)
        x = self.norm(x)
        return x

class Mlp(nn.Module):
    def __init__(self, in_features, hidden_features=None,
                 out_features=None, act_layer=nn.GELU, drop=0.,
                 conv2d = nn.Conv2d
                 ):
        super().__init__()
        out_features = out_features or in_features
        hidden_features = hidden_features or in_features
        self.fc1 = conv2d(in_features, hidden_features, 1)
        self.act = act_layer()
        self.fc2 = conv2d(hidden_features, out_features, 1)
        self.drop = nn.Dropout(drop)

    def forward(self, x):
        x = self.fc1(x)
        x = self.act(x)
        x = self.drop(x)
        x = self.fc2(x)
        x = self.drop(x)
        return x

class SpatialOperation(nn.Module):
    def __init__(self, dim, conv2d = nn.Conv2d):
        super().__init__()
        self.block = nn.Sequential(
            conv2d(dim, dim, 3, 1, 1, groups=dim),
            nn.BatchNorm2d(dim),
            nn.ReLU(True),
            conv2d(dim, 1, 1, 1, 0, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return x * self.block(x)

class ChannelOperation(nn.Module):
    def __init__(self, dim, conv2d = nn.Conv2d):
        super().__init__()
        self.block = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            conv2d(dim, dim, 1, 1, 0, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return x * self.block(x)

class LocalIntegration(nn.Module):
    def __init__(self, dim, ratio=1,
                 act_layer=nn.ReLU, norm_layer=nn.GELU,
                 conv2d = nn.Conv2d):
        super().__init__()
        mid_dim = round(ratio * dim)
        self.network = nn.Sequential(
            conv2d(dim, mid_dim, 1, 1, 0),
            norm_layer(mid_dim),
            conv2d(mid_dim, mid_dim, 3, 1, 1, groups=mid_dim),
            act_layer(),
            conv2d(mid_dim, dim, 1, 1, 0),
        )

    def forward(self, x):
        return self.network(x)


class AdditiveTokenMixer(nn.Module):
    def __init__(self, dim=512, attn_bias=False, proj_drop=0.,
                 conv2d = nn.Conv2d):
        super().__init__()
        self.qkv = conv2d(dim, 3 * dim, 1, stride=1, padding=0, bias=attn_bias)
        self.oper_q = nn.Sequential(
            SpatialOperation(dim, conv2d = conv2d),
            ChannelOperation(dim, conv2d = conv2d),
        )
        self.oper_k = nn.Sequential(
            SpatialOperation(dim, conv2d = conv2d),
            ChannelOperation(dim, conv2d = conv2d),
        )
        self.dwc = conv2d(dim, dim, 3, 1, 1, groups=dim)

        self.proj = conv2d(dim, dim, 3, 1, 1, groups=dim)
        self.proj_drop = nn.Dropout(proj_drop)

    def forward(self, x):
        q, k, v = self.qkv(x).chunk(3, dim=1)
        q = self.oper_q(q)
        k = self.oper_k(k)
        out = self.proj(self.dwc(q + k) * v)
        out = self.proj_drop(out)
        return out



class AdditiveBlock(nn.Module):
    def __init__(self, dim, mlp_ratio=4., attn_bias=False, drop=0., drop_path=0.,
                 act_layer=nn.ReLU, norm_layer=nn.GELU, conv2d = nn.Conv2d):
        super().__init__()
        self.local_perception = LocalIntegration(dim, ratio=1, act_layer=act_layer, norm_layer=norm_layer)
        self.norm1 = norm_layer(dim)
        self.attn = AdditiveTokenMixer(dim, attn_bias=attn_bias, proj_drop=drop)
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()

        self.norm2 = norm_layer(dim)
        mlp_hidden_dim = int(dim * mlp_ratio)
        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop, conv2d = conv2d)

    def forward(self, x):
        x = x + self.local_perception(x)
        x = x + self.drop_path(self.attn(self.norm1(x)))
        x = x + self.drop_path(self.mlp(self.norm2(x)))
        return x

def Stage(dim, index, layers, mlp_ratio=4., act_layer=nn.GELU, attn_bias=False, drop=0., drop_path_rate=0., conv2d = nn.Conv2d):
    blocks = []
    for block_idx in range(layers[index]):
        block_dpr = drop_path_rate * (block_idx + sum(layers[:index])) / (sum(layers) - 1)

        blocks.append(
            AdditiveBlock(
                dim, mlp_ratio=mlp_ratio, attn_bias=attn_bias, drop=drop, drop_path=block_dpr,
                act_layer=act_layer, norm_layer=nn.BatchNorm2d,
                conv2d = conv2d
                )
        )
    blocks = nn.Sequential(*blocks)
    return blocks

class RCViT(nn.Module):
    def __init__(self, layers, embed_dims, mlp_ratios=4, downsamples=[True, True, True, True], norm_layer=nn.BatchNorm2d, attn_bias=False,
                 act_layer=nn.GELU, num_classes=1000, drop_rate=0., drop_path_rate=0.,
                 init_cfg=None, pretrained=None, distillation=True,
                 linear = nn.Linear, conv2d = nn.Conv2d,
                 **kwargs):
        super().__init__()
        self.linear = linear
        self.conv2d = conv2d

        self.num_classes = num_classes
        self.patch_embed = stem(3, embed_dims[0])

        network = []
        for i in range(len(layers)):
            stage = Stage(embed_dims[i], i, layers, mlp_ratio=mlp_ratios, act_layer=act_layer,
                          attn_bias=attn_bias, drop=drop_rate, drop_path_rate=drop_path_rate, conv2d = conv2d)

            network.append(stage)
            if i >= len(layers) - 1:
                break
            if downsamples[i] or embed_dims[i] != embed_dims[i + 1]:
                # downsampling between two stages
                network.append(
                    Embedding(
                        patch_size=3, stride=2, padding=1, in_chans=embed_dims[i],
                        embed_dim=embed_dims[i+1], norm_layer=nn.BatchNorm2d)
                )

        self.network = nn.ModuleList(network)

        # Classifier head
        self.norm = norm_layer(embed_dims[-1])
        self.head = linear(
            embed_dims[-1], num_classes) if num_classes > 0 \
            else nn.Identity()
        self.dist = distillation
        if self.dist:
            self.dist_head = linear(
                embed_dims[-1], num_classes) if num_classes > 0 \
                else nn.Identity()

        # self.apply(self.cls_init_weights)

        self.init_cfg = copy.deepcopy(init_cfg)

    # # init for classification
    # def cls_init_weights(self, m):
    #     if isinstance(m, self.linear):
    #         trunc_normal_(m.weight, std=.02)
    #         if isinstance(m, self.linear) and m.bias is not None:
    #             nn.init.constant_(m.bias, 0)

    def init_weights(self, pretrained=None):
        pass

    def forward_tokens(self, x):
        outs = []
        for idx, block in enumerate(self.network):
            x = block(x)
        return x

    def forward(self, x):
        x = self.patch_embed(x)
        x = self.forward_tokens(x)
        x = self.norm(x)
        cls_out = self.head(x.flatten(2).mean(-1))
        return cls_out

# ======================================================================================================================

# def rcvit_xs(**kwargs):
#     model = RCViT(
#         layers=[2, 2, 4, 2], embed_dims=[48, 56, 112, 220], mlp_ratios=4, downsamples=[True, True, True, True],
#         norm_layer=nn.BatchNorm2d, attn_bias=False, act_layer=nn.GELU, linear = btnnLinear, conv2d = btnnConv2d, drop_rate=0.,
#         fork_feat=False, init_cfg=None, **kwargs)
#     return model

def rcvit_xs(linear = nn.Linear, conv2d = nn.Conv2d, **kwargs):
    model = RCViT(
        layers=[2, 2, 4, 2], embed_dims=[48, 56, 112, 220], mlp_ratios=4, downsamples=[True, True, True, True],
        norm_layer=nn.BatchNorm2d, attn_bias=False, act_layer=nn.GELU, drop_rate=0.,
        linear = linear, conv2d = conv2d,
        **kwargs)
    return model

"""# Training Module"""

import torch
from torch import nn
from torch.optim import Adam
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
import pytorch_lightning as pl

# LightningModule 정의
class LitModel(pl.LightningModule):
    def __init__(self, linear = nn.Linear, conv2d = nn.Conv2d):
        super().__init__()

        self.model = rcvit_xs(num_classes=100, linear = linear, conv2d = conv2d)
        self.criterion = nn.CrossEntropyLoss()

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)

        preds = torch.argmax(logits, dim=1)
        acc = (preds == y).float().mean()

        # Batch 단위 결과 로깅
        self.log("train_loss", loss, prog_bar=True)
        self.log("train_acc", acc, prog_bar=True)
        return {"loss": loss, "accuracy": acc}

    def train_epoch_end(self, outputs):
        # 에포크 단위 결과 요약
        avg_loss = torch.stack([x["loss"] for x in outputs]).mean()
        avg_acc = torch.stack([x["accuracy"] for x in outputs]).mean()
        print(f"\nEpoch End - Train Loss: {avg_loss:.4f}, Train Accuracy: {avg_acc:.4f}")

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)

        preds = torch.argmax(logits, dim=1)
        acc = (preds == y).float().mean()

        # Batch 단위 결과 로깅
        self.log("val_acc", acc, prog_bar=True)
        return {"val_accuracy": acc}

    def validation_step_epoch_end(self, outputs):
        # 에포크 단위 결과 요약
        avg_acc = torch.stack([x["val_accuracy"] for x in outputs]).mean()
        print(f"Validation Accuracy: {avg_acc:.4f}")

    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)
        preds = torch.argmax(logits, dim=1)
        acc = (preds == y).float().mean()
        self.log("test_accuracy", acc)
        return {"test_accuracy": acc}

    def configure_optimizers(self):
        return Adam(self.parameters(), lr=0.001)

"""# Data Module"""

import pytorch_lightning as pl
from torch.utils.data import DataLoader
from torchvision import transforms, datasets

class CIFAR100DataModule(pl.LightningDataModule):
    def __init__(self, data_dir="./", batch_size=64):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size

        # 데이터 전처리 변환 정의
        self.transform_train = transforms.Compose([
            transforms.ToTensor(),
        ])

        self.transform_test = transforms.Compose([
            transforms.ToTensor(),
        ])

    def prepare_data(self):
        # 데이터셋 다운로드
        datasets.CIFAR100(self.data_dir, train=True, download=True)
        datasets.CIFAR100(self.data_dir, train=False, download=True)

    def setup(self, stage=None):
        # 데이터셋 정의
        if stage == "fit" or stage is None:
            self.cifar_train = datasets.CIFAR100(self.data_dir, train=True, transform=self.transform_train)
            self.cifar_val = datasets.CIFAR100(self.data_dir, train=True, transform=self.transform_test)

            # 훈련/검증 나누기
            val_size = 5000
            train_size = len(self.cifar_train) - val_size
            self.cifar_train, self.cifar_val = torch.utils.data.random_split(self.cifar_train, [train_size, val_size])

        if stage == "test" or stage is None:
            self.cifar_test = datasets.CIFAR100(self.data_dir, train=False, transform=self.transform_test)

    def train_dataloader(self):
        return DataLoader(self.cifar_train, batch_size=self.batch_size, shuffle=True, num_workers=4)

    def val_dataloader(self):
        return DataLoader(self.cifar_val, batch_size=self.batch_size, shuffle=False, num_workers=4)

    def test_dataloader(self):
        return DataLoader(self.cifar_test, batch_size=self.batch_size, shuffle=False, num_workers=4)

"""# Train Test"""

# 학습 및 테스트 실행
if __name__ == "__main__":
    model = LitModel(linear = btnnLinear, conv2d = btnnConv2d)
    data_module = CIFAR100DataModule(batch_size=64)

    device = "gpu" if torch.cuda.is_available() else "cpu"
    print(device)
    # 학습
    logger = pl.loggers.CSVLogger("logs", name = "CIFAR100_BT_CASViT")
    trainer = pl.Trainer(max_epochs=5, devices = 1, accelerator=device, logger = logger)
    trainer.fit(model, data_module)

    # 테스트
    test_results = trainer.test(datamodule=data_module)
    print("Test Results:", test_results)

# 학습 및 테스트 실행
if __name__ == "__main__":
    model = LitModel()
    data_module = CIFAR100DataModule(batch_size=64)

    device = "gpu" if torch.cuda.is_available() else "cpu"
    print(device)
    # 학습
    logger = pl.loggers.CSVLogger("logs", name = "CIFAR100_CASViT")
    trainer = pl.Trainer(max_epochs=5, devices = 1, accelerator=device, logger = logger)
    trainer.fit(model, data_module)

    # 테스트
    test_results = trainer.test(datamodule=data_module)
    print("Test Results:", test_results)

import pandas as pd
import matplotlib.pyplot as plt

# 두 모델의 metrics.csv 파일 경로
paths = {
    "BT_CASViT": "/content/logs/CIFAR100_BT_CASViT/version_0/metrics.csv",
    "CASViT": "/content/logs/CIFAR100_CASViT/version_0/metrics.csv"
}

# 데이터를 로드하고 처리
data = {}
for model_name, path in paths.items():
    df = pd.read_csv(path)

    # train 데이터와 validation 데이터 필터링
    df_train = df[df["train_acc"].notna()]  # train 데이터 (step 단위)
    df_val = df[df["val_acc"].notna()]  # validation 데이터 (epoch 단위)

    data[model_name] = {
        "train_step": df_train["step"].values,
        "train_acc": df_train["train_acc"].values,
        "train_loss": df_train["train_loss"].values,
        "val_epoch": range(1, len(df_val) + 1),  # epoch 번호
        "val_acc": df_val["val_acc"].values
    }

save_dir = "/content/logs/"

# Training Accuracy 그래프
plt.figure(figsize=(12, 6))
for model_name in data:
    plt.plot(data[model_name]["train_step"], data[model_name]["train_acc"], label=f"{model_name} Train Accuracy")
plt.title("Training Accuracy")
plt.xlabel("Step")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.savefig(f"{save_dir}training_accuracy.png")
plt.close()

# Training Loss 그래프
plt.figure(figsize=(12, 6))
for model_name in data:
    plt.plot(data[model_name]["train_step"], data[model_name]["train_loss"], label=f"{model_name} Train Loss")
plt.title("Training Loss")
plt.xlabel("Step")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.savefig(f"{save_dir}training_loss.png")
plt.close()

# Validation Accuracy 그래프
plt.figure(figsize=(12, 6))
for model_name in data:
    plt.plot(data[model_name]["val_epoch"], data[model_name]["val_acc"], marker='o', linestyle='--', label=f"{model_name} Validation Accuracy")
plt.title("Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.savefig(f"{save_dir}validation_accuracy.png")
plt.close()